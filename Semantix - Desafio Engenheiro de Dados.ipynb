{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Semantix</font>\n",
    "## <font color='blue'>Desafio Engenheiro de Dados</font>\n",
    "<br/>\n",
    "### Thiago de Lucena Nascimento\n",
    "\n",
    "<b>Email:</b> thiago_lucena@hotmail.com.br\n",
    "\n",
    "<b>LinkedIn:</b> https://br.linkedin.com/pub/thiago-de-lucena-nascimento/85/b80/587\n",
    "\n",
    "<b>Contato:</b> (11)96358-7940\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual o objetivo do comando <u>cache</u> em Spark?\n",
    "Possibilita a persistencia dos dados em memória, permitindo que sejam reutilizados em etapas seguintes evitando um novo processamento.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O mesmo código implementado em Spark é normalmente mais rápido que a implementação equivalente em MapReduce. Por quê?\n",
    "O MapReduce utiliza-se do disco (HDFS) para realizar a gravação dos resultados intermediários em uma atividade de processamento, ao passo que o Spark utiliza-se da memória.\n",
    "O processamento em memória é até 100x mais rápido.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual é a função do <u>SparkContext</u>?\n",
    "Estabelecer a conexão com o ambiente de execução do Spark, permitindo acesso à todas as suas funcionalidades.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explique com suas palavras  o que é <u>Resilient Distributed Datasets (RDD)</u>.\n",
    "É uma coleção de elementos de dados particionados distribuída e imutável.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>GroupByKey</u> é menos eficiente que <u>reduceByKey</u> em grandes dataset. Por quê?\n",
    "O GroupByKey realiza o agrupamento de todos os dados de diferentes partições para só então realizar a operação.\n",
    "O reduceByKey realiza o agrupamento dos dados por partição para depois realizar a operação. Isso implica em um volume menor de dados trafegando na rede.\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explique o que o código Scala abaixo faz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">val textFile = sc.textFile(\"hdfs://...\")</font>\n",
    "<font color=green><i>#CRIA UM RDD A PARTIR DE UM ARQUIVO DO HDFS</i></font> <br/>\n",
    "<font size=\"4\">val counts = textFile.flatMap(line => line.split(\" \")</font>\n",
    "<font color=green><i>#APLICA O SPLIT PARA QUEBRAR O RDD EM PALAVRAS</i></font> <br/>\n",
    "    <font size=\"4\">.map(word => (word, 1))</font>\n",
    "    <font color=green><i>#FAZ UM MAPEAMENTO \"CHAVE, VALOR\" DE CADA PALAVRA ATRIBUINDO O VALOR 1<i></font> <br/>\n",
    "    <font size=\"4\">.reduceByKey(_ + _)</font>\n",
    "    <font color=green><i>#FAZ REDUÇÃO SUMARIZANDO OS VALORES POR PALAVRAS, RESULTANDO NA QUANTIDADE TOTAL DE CADA PALAVRA</i></font> <br/>\n",
    "<font size=\"4\">counts.saveAsTextFile(\"hdfs://...\")</font>\n",
    "<font color=green><i>#SALVA O ARQUIVO COM A CONTAGEM DE REPETIÇÃO DAS PALAVRAS NO HDFS</i></font>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>HTTP requests to the NASA Kennedy Space Center WWW server</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import regexp_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o Spark Session\n",
    "spSession = SparkSession.builder.master(\"local\").appName(\"Semantix-Desafio\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o SQL Context\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unindo os dois arquivos\n",
    "Jul95 = sqlContext.read.text(\"access_log_Jul95\")\n",
    "Aug95 = sqlContext.read.text(\"access_log_Aug95\")\n",
    "NASA_Jul95_Aug95 = Jul95.union(Aug95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as colunas através de expressões regulares\n",
    "NASA = NASA_Jul95_Aug95.select(regexp_extract('value', r'^([^\\s]+)', 1).alias('HOST'),\n",
    "regexp_extract('value', r'^.*\\[(\\d\\d/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]', 1).alias('TIMESTAMP'),\n",
    "regexp_extract('value', r'^.*\"\\w+\\s+([^\\s]+)\\s+HTTP.*\"', 1).alias('REQUISICAO'),\n",
    "regexp_extract('value', r'^.*\"\\s+([^\\s]+)', 1).cast('integer').alias('RETORNO'),\n",
    "regexp_extract('value', r'^.*\\s+(\\d+)$', 1).cast('integer').alias('BYTES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma Tabela Temporaria\n",
    "NASA.createOrReplaceTempView(\"NASA_TEMP_TAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Questões</fonte>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Número de hosts únicos.\n",
    "Nesta questão fiquei em dúvida de como deveriam ser apresentados os resultados. Então, fiz duas consultas, uma com o total e outra listando os hosts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|TOTAL|\n",
      "+-----+\n",
      "| 9269|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spSession.sql(\"SELECT SUM(CONTAGEM) as TOTAL \\\n",
    "               FROM (SELECT COUNT(1) as CONTAGEM \\\n",
    "                     FROM NASA_TEMP_TAB \\\n",
    "                     GROUP BY HOST \\\n",
    "                     HAVING COUNT(1) <2) \\\n",
    "               DISTINTOS\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|CONTAGEM|                HOST|\n",
      "+--------+--------------------+\n",
      "|       1|     193.166.184.116|\n",
      "|       1|      204.120.34.242|\n",
      "|       1|dutton.cmdl.noaa.gov|\n",
      "|       1|    rickf.seanet.com|\n",
      "|       1|  vdfcomm.vdfnet.com|\n",
      "|       1|ldvgpi33.ldv.e-te...|\n",
      "|       1|tenebris.rutgers.edu|\n",
      "|       1|       144.191.11.42|\n",
      "|       1|inf-pc43.fbm.htw-...|\n",
      "|       1|       conan.ids.net|\n",
      "|       1|   obiwan.tdtech.com|\n",
      "|       1|      204.180.143.17|\n",
      "|       1|n1-28-222.macip.d...|\n",
      "|       1|      chi007.wwa.com|\n",
      "|       1|       137.148.36.27|\n",
      "|       1|       129.219.88.17|\n",
      "|       1|       nu.sim.es.com|\n",
      "|       1|jobstgb1.bradley.edu|\n",
      "|       1|ip-pdx1-51.telepo...|\n",
      "|       1|       194.20.140.83|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spSession.sql(\"SELECT COUNT(1) as CONTAGEM, \\\n",
    "                      HOST \\\n",
    "                      FROM NASA_TEMP_TAB \\\n",
    "                      GROUP BY HOST \\\n",
    "                      HAVING COUNT(1) <2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. O total de erros 404."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|TOTAL_ERRO|\n",
      "+----------+\n",
      "|     20901|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spSession.sql(\"SELECT COUNT(1) as TOTAL_ERRO \\\n",
    "               FROM NASA_TEMP_TAB \\\n",
    "               WHERE RETORNO=404\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Os 5 URLs que mais causaram erro 404."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|TOTAL|                 URL|\n",
      "+-----+--------------------+\n",
      "| 2004|/pub/winvn/readme...|\n",
      "| 1732|/pub/winvn/releas...|\n",
      "|  682|/shuttle/missions...|\n",
      "|  426|/shuttle/missions...|\n",
      "|  384|/history/apollo/a...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spSession.sql(\"SELECT COUNT(1) as TOTAL, \\\n",
    "               REQUISICAO as URL \\\n",
    "               FROM NASA_TEMP_TAB \\\n",
    "               WHERE RETORNO=404 \\\n",
    "               GROUP BY REQUISICAO \\\n",
    "               ORDER BY COUNT(1) DESC \\\n",
    "               LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Quantidade de erros 404 por dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|TOTAL_ERRO|        DIA|\n",
      "+----------+-----------+\n",
      "|       291|02/Jul/1995|\n",
      "|       305|21/Aug/1995|\n",
      "|       373|06/Aug/1995|\n",
      "|       257|16/Jul/1995|\n",
      "|       537|07/Aug/1995|\n",
      "|       263|11/Aug/1995|\n",
      "|       336|27/Jul/1995|\n",
      "|       570|07/Jul/1995|\n",
      "|       406|17/Jul/1995|\n",
      "|       254|15/Jul/1995|\n",
      "|       465|18/Jul/1995|\n",
      "|       336|26/Jul/1995|\n",
      "|       304|03/Aug/1995|\n",
      "|       256|18/Aug/1995|\n",
      "|       271|17/Aug/1995|\n",
      "|       287|14/Aug/1995|\n",
      "|       398|10/Jul/1995|\n",
      "|       359|04/Jul/1995|\n",
      "|       312|20/Aug/1995|\n",
      "|       428|20/Jul/1995|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spSession.sql(\"SELECT COUNT(1) as TOTAL_ERRO, \\\n",
    "               SUBSTR(TIMESTAMP, 1, 11) as DIA \\\n",
    "               FROM NASA_TEMP_TAB \\\n",
    "               WHERE RETORNO=404 \\\n",
    "               GROUP BY SUBSTR(TIMESTAMP, 1, 11)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. O total de bytes retornados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|TOTAL_BYTES|\n",
      "+-----------+\n",
      "|65524314915|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spSession.sql(\"SELECT SUM(BYTES) as TOTAL_BYTES \\\n",
    "               FROM NASA_TEMP_TAB\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
